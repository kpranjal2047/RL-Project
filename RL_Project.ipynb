{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL Project",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l50jAc9uNDz8"
      },
      "source": [
        "# Deep Reinforcement Learning for List-wise Recommendations\n",
        "\n",
        "Implemented by:\n",
        " - Radhika Sigtia - 2019A7PS0094H\n",
        " - Shreyas Gupta - 2019A7PS0121H\n",
        " - Kumar Pranjal - 2018A7PS0163H\n",
        " - Ritvik Upadhyay - 2019A7PS0163H"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VCoNiElLnK4"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKmjjI_7qfaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9265414f-f1de-4e94-a443-4e8f504f7ccf"
      },
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import csv\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "import keras.backend as K\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Dropout"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwoaes5UyJJS"
      },
      "source": [
        "# MovieLens 100k Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2H9eM4YuOy6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "493052e2-29e5-4bb4-abb3-8d26eb1aa668"
      },
      "source": [
        "!wget http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
        "!unzip -q ml-100k.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-30 18:26:27--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘ml-100k.zip’\n",
            "\n",
            "ml-100k.zip         100%[===================>]   4.70M  29.5MB/s    in 0.2s    \n",
            "\n",
            "2021-11-30 18:26:28 (29.5 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yST4dc3wtm2T"
      },
      "source": [
        "class DataGenerator():\n",
        "  def __init__(self, datapath, itempath):\n",
        "    '''\n",
        "    Load data from the DB MovieLens\n",
        "    List the users and the items\n",
        "    List all the users historic\n",
        "    '''\n",
        "    self.data  = self.load_datas(datapath, itempath)\n",
        "    self.users = self.data['userId'].unique()   #list of all users\n",
        "    self.items = self.data['itemId'].unique()   #list of all items\n",
        "    self.histo = self.gen_histo()\n",
        "    self.train = []\n",
        "    self.test  = []\n",
        "\n",
        "  def load_datas(self, datapath, itempath):\n",
        "    '''\n",
        "    Load the data and merge the name of each movie. \n",
        "    A row corresponds to a rate given by a user to a movie.\n",
        "\n",
        "     Parameters\n",
        "    ----------\n",
        "    datapath :  string\n",
        "                path to the data 100k MovieLens\n",
        "                contains usersId;itemId;rating \n",
        "    itempath :  string\n",
        "                path to the data 100k MovieLens\n",
        "                contains itemId;itemName\n",
        "     Returns\n",
        "    -------\n",
        "    result :    DataFrame\n",
        "                Contains all the ratings \n",
        "    '''\n",
        "    data = pd.read_csv(datapath, sep='\\t', \n",
        "                       names=['userId', 'itemId', 'rating', 'timestamp'])\n",
        "    movie_titles = pd.read_csv(itempath, sep='|', names=['itemId', 'itemName'],\n",
        "                           usecols=range(2), encoding='latin-1')\n",
        "    return data.merge(movie_titles,on='itemId', how='left')\n",
        "\n",
        "\n",
        "  def gen_histo(self):\n",
        "    '''\n",
        "    Group all rates given by users and store them from older to most recent.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    result :    List(DataFrame)\n",
        "                List of the historic for each user\n",
        "    '''\n",
        "    historic_users = []\n",
        "    for i, u in enumerate(self.users):\n",
        "      temp = self.data[self.data['userId'] == u]\n",
        "      temp = temp.sort_values('timestamp').reset_index()\n",
        "      temp.drop('index', axis=1, inplace=True)\n",
        "      historic_users.append(temp)\n",
        "    return historic_users\n",
        "\n",
        "  def sample_histo(self, user_histo, action_ratio=0.8, max_samp_by_user=5,  max_state=100, max_action=50, nb_states=[], nb_actions=[]):\n",
        "    '''\n",
        "    For a given historic, make one or multiple sampling.\n",
        "    If no optional argument given for nb_states and nb_actions, then the sampling\n",
        "    is random and each sample can have differents size for action and state.\n",
        "    To normalize sampling we need to give list of the numbers of states and actions\n",
        "    to be sampled.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    user_histo :  DataFrame\n",
        "                      historic of user\n",
        "    delimiter :       string, optional\n",
        "                      delimiter for the csv\n",
        "    action_ratio :    float, optional\n",
        "                      ratio form which movies in history will be selected\n",
        "    max_samp_by_user: int, optional\n",
        "                      Nulber max of sample to make by user\n",
        "    max_state :       int, optional\n",
        "                      Number max of movies to take for the 'state' column\n",
        "    max_action :      int, optional\n",
        "                      Number max of movies to take for the 'action' action\n",
        "    nb_states :       array(int), optional\n",
        "                      Numbers of movies to be taken for each sample made on user's historic\n",
        "    nb_actions :      array(int), optional\n",
        "                      Numbers of rating to be taken for each sample made on user's historic\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    states :         List(String)\n",
        "                     All the states sampled, format of a sample: itemId&rating\n",
        "    actions :        List(String)\n",
        "                     All the actions sampled, format of a sample: itemId&rating\n",
        "  \n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    States must be before(timestamp<) the actions.\n",
        "    If given, size of nb_states is the numbller of sample by user\n",
        "    sizes of nb_states and nb_actions must be equals\n",
        "    '''\n",
        "\n",
        "    n = len(user_histo)\n",
        "    sep = int(action_ratio * n)\n",
        "    nb_sample = random.randint(1, max_samp_by_user)\n",
        "    if not nb_states:\n",
        "      nb_states = [min(random.randint(1, sep), max_state) for i in range(nb_sample)]\n",
        "    if not nb_actions:\n",
        "      nb_actions = [min(random.randint(1, n - sep), max_action) for i in range(nb_sample)]\n",
        "    assert len(nb_states) == len(nb_actions), 'Given array must have the same size'\n",
        "    \n",
        "    states  = []\n",
        "    actions = []\n",
        "    ## SELECT SAMPLES IN HISTO\n",
        "    for i in range(len(nb_states)):\n",
        "      sample_states = user_histo.iloc[0:sep].sample(nb_states[i])\n",
        "      sample_actions = user_histo.iloc[-(n - sep):].sample(nb_actions[i])\n",
        "      \n",
        "      sample_state =  []\n",
        "      sample_action = []\n",
        "      for j in range(nb_states[i]):\n",
        "        row   = sample_states.iloc[j]\n",
        "        ## FORMAT STATE\n",
        "        state = str(row.loc['itemId']) + '&' + str(row.loc['rating'])\n",
        "        sample_state.append(state)\n",
        "      \n",
        "      for j in range(nb_actions[i]):\n",
        "        row    = sample_actions.iloc[j]\n",
        "        ## FORMAT ACTION\n",
        "        action = str(row.loc['itemId']) + '&' + str(row.loc['rating'])\n",
        "        sample_action.append(action)\n",
        "\n",
        "      states.append(sample_state)\n",
        "      actions.append(sample_action)\n",
        "    return states, actions\n",
        "\n",
        "  def gen_train_test(self, test_ratio, seed=None):\n",
        "    '''\n",
        "    Shuffle the historic of users and separate it in a train and a test set.\n",
        "    Store the ids for each set.\n",
        "    An user can't be in both set.\n",
        "\n",
        "     Parameters\n",
        "    ----------\n",
        "    test_ratio :  float\n",
        "                  Ratio to control the sizes of the sets\n",
        "    seed       :  float\n",
        "                  Seed on the shuffle\n",
        "    '''\n",
        "    n = len(self.histo)\n",
        "\n",
        "    if seed is not None:\n",
        "      random.Random(seed).shuffle(self.histo)\n",
        "    else:\n",
        "      random.shuffle(self.histo)\n",
        "\n",
        "    self.train = self.histo[:int((test_ratio * n))]\n",
        "    self.test  = self.histo[int((test_ratio * n)):]\n",
        "    self.user_train = [h.iloc[0,0] for h in self.train]\n",
        "    self.user_test  = [h.iloc[0,0] for h in self.test]\n",
        "    \n",
        "\n",
        "  def write_csv(self, filename, histo_to_write, delimiter=';', action_ratio=0.8, max_samp_by_user=5, max_state=100, max_action=50, nb_states=[], nb_actions=[]):\n",
        "    '''\n",
        "    From  a given historic, create a csv file with the format:\n",
        "    columns : state;action_reward;n_state\n",
        "    rows    : itemid&rating1 | itemid&rating2 | ... ; itemid&rating3 | ... | itemid&rating4; itemid&rating1 | itemid&rating2 | itemid&rating3 | ... | item&rating4\n",
        "    at filename location.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    filename :        string\n",
        "                      path to the file to be produced\n",
        "    histo_to_write :  List(DataFrame)\n",
        "                      List of the historic for each user\n",
        "    delimiter :       string, optional\n",
        "                      delimiter for the csv\n",
        "    action_ratio :    float, optional\n",
        "                      ratio form which movies in history will be selected\n",
        "    max_samp_by_user: int, optional\n",
        "                      Nulber max of sample to make by user\n",
        "    max_state :       int, optional\n",
        "                      Number max of movies to take for the 'state' column\n",
        "    max_action :      int, optional\n",
        "                      Number max of movies to take for the 'action' action\n",
        "    nb_states :       array(int), optional\n",
        "                      Numbers of movies to be taken for each sample made on user's historic\n",
        "    nb_actions :      array(int), optional\n",
        "                      Numbers of rating to be taken for each sample made on user's historic\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    if given, size of nb_states is the numbller of sample by user\n",
        "    sizes of nb_states and nb_actions must be equals\n",
        "\n",
        "    '''\n",
        "    with open(filename, mode='w') as file:\n",
        "      f_writer = csv.writer(file, delimiter=delimiter)\n",
        "      f_writer.writerow(['state', 'action_reward', 'n_state'])\n",
        "      for user_histo in histo_to_write:\n",
        "        states, actions = self.sample_histo(user_histo, action_ratio, max_samp_by_user, max_state, max_action, nb_states, nb_actions)\n",
        "        for i in range(len(states)):\n",
        "          ## FORMAT STATE\n",
        "          state_str   = '|'.join(states[i])\n",
        "          ## FORMAT ACTION\n",
        "          action_str  = '|'.join(actions[i])\n",
        "          ## FORMAT N_STATE\n",
        "          n_state_str = state_str + '|' + action_str\n",
        "          f_writer.writerow([state_str, action_str, n_state_str])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfGFFQeZyQfG"
      },
      "source": [
        "# Movies Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "578-inzm24sj"
      },
      "source": [
        "class EmbeddingsGenerator:\n",
        "  def  __init__(self, train_users, data):\n",
        "    self.train_users = train_users\n",
        "\n",
        "    ## preprocess\n",
        "    self.data = data.sort_values(by=['timestamp'])\n",
        "    ## make them start at 0\n",
        "    self.data['userId'] = self.data['userId'] - 1\n",
        "    self.data['itemId'] = self.data['itemId'] - 1\n",
        "    self.user_count = self.data['userId'].max() + 1\n",
        "    self.movie_count = self.data['itemId'].max() + 1\n",
        "    self.user_movies = {} #list of rated movies by each user\n",
        "    for userId in range(self.user_count):\n",
        "      self.user_movies[userId] = self.data[self.data.userId == userId]['itemId'].tolist()\n",
        "    self.m = self.model()\n",
        "\n",
        "  def model(self, hidden_layer_size=100):\n",
        "    m = Sequential()\n",
        "    m.add(Dense(hidden_layer_size, input_shape=(1, self.movie_count)))\n",
        "    m.add(Dropout(0.2))\n",
        "    m.add(Dense(self.movie_count, activation='softmax'))\n",
        "    m.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return m\n",
        "  \n",
        "  def generate_input(self, user_id):\n",
        "    '''\n",
        "    Returns a context and a target for the user_id\n",
        "    context: user's history with one random movie removed\n",
        "    target: id of random removed movie\n",
        "    '''\n",
        "    user_movies_count = len(self.user_movies[user_id])\n",
        "    ## picking random movie\n",
        "    random_index = np.random.randint(0, user_movies_count-1) # -1 avoids taking the last movie\n",
        "    ## setting target\n",
        "    target = np.zeros((1, self.movie_count))\n",
        "    target[0][self.user_movies[user_id][random_index]] = 1\n",
        "    ## setting context\n",
        "    context = np.zeros((1, self.movie_count))\n",
        "    context[0][self.user_movies[user_id][:random_index] + self.user_movies[user_id][random_index+1:]] = 1\n",
        "    return context, target\n",
        "\n",
        "  def train(self, nb_epochs = 300, batch_size = 10000):\n",
        "    '''\n",
        "    Trains the model from train_users's history\n",
        "    '''\n",
        "    for i in range(nb_epochs):\n",
        "      print('%d/%d' % (i+1, nb_epochs))\n",
        "      batch = [self.generate_input(user_id=np.random.choice(self.train_users) - 1) for _ in range(batch_size)]\n",
        "      X_train = np.array([b[0] for b in batch])\n",
        "      y_train = np.array([b[1] for b in batch])\n",
        "      self.m.fit(X_train, y_train, epochs=1, validation_split=0.5)\n",
        "\n",
        "  def test(self, test_users, batch_size = 100000):\n",
        "    '''\n",
        "    Returns [loss, accuracy] on the test set\n",
        "    '''\n",
        "    batch_test = [self.generate_input(user_id=np.random.choice(test_users) - 1) for _ in range(batch_size)]\n",
        "    X_test = np.array([b[0] for b in batch_test])\n",
        "    y_test = np.array([b[1] for b in batch_test])\n",
        "    return self.m.evaluate(X_test, y_test)\n",
        "\n",
        "  def save_embeddings(self, file_name):\n",
        "    '''\n",
        "    Generates a csv file containg the vector embedding for each movie.\n",
        "    '''\n",
        "    inp = self.m.input                                           # input placeholder\n",
        "    outputs = [layer.output for layer in self.m.layers]          # all layer outputs\n",
        "    functor = K.function([inp, K.learning_phase()], outputs )   # evaluation function\n",
        "\n",
        "    ## append embeddings to vectors\n",
        "    vectors = []\n",
        "    for movie_id in range(self.movie_count):\n",
        "      movie = np.zeros((1, 1, self.movie_count))\n",
        "      movie[0][0][movie_id] = 1\n",
        "      layer_outs = functor([movie])\n",
        "      vector = [str(v) for v in layer_outs[0][0][0]]\n",
        "      vector = '|'.join(vector)\n",
        "      vectors.append([movie_id, vector])\n",
        "\n",
        "    ## saves as a csv file\n",
        "    embeddings = pd.DataFrame(vectors, columns=['item_id', 'vectors']).astype({'item_id': 'int32'})\n",
        "    embeddings.to_csv(file_name, sep=';', index=False)\n",
        "    files.download(file_name) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpKB5xexLvSI"
      },
      "source": [
        "class Embeddings:\n",
        "  def __init__(self, item_embeddings):\n",
        "    self.item_embeddings = item_embeddings\n",
        "  \n",
        "  def size(self):\n",
        "    return self.item_embeddings.shape[1]\n",
        "  \n",
        "  def get_embedding_vector(self):\n",
        "    return self.item_embeddings\n",
        "  \n",
        "  def get_embedding(self, item_index):\n",
        "    return self.item_embeddings[item_index-1]\n",
        "\n",
        "  def embed(self, item_list):\n",
        "    return np.array([self.get_embedding(item) for item in item_list])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AolIkmf0LWZP"
      },
      "source": [
        "def read_file(data_path):\n",
        "  ''' Load data from train.csv or test.csv. '''\n",
        "\n",
        "  data = pd.read_csv(data_path, sep=';')\n",
        "  for col in ['state', 'n_state', 'action_reward']:\n",
        "    data[col] = [np.array([[np.int(k) for k in ee.split('&')] for ee in e.split('|')]) for e in data[col]]\n",
        "  for col in ['state', 'n_state']:\n",
        "    data[col] = [np.array([e[0] for e in l]) for l in data[col]]\n",
        "\n",
        "  data['action'] = [[e[0] for e in l] for l in data['action_reward']]\n",
        "  data['reward'] = [tuple(e[1] for e in l) for l in data['action_reward']]\n",
        "  data.drop(columns=['action_reward'], inplace=True)\n",
        "\n",
        "  return data\n",
        "\n",
        "def read_embeddings(embeddings_path):\n",
        "  ''' Load embeddings (a vector for each item). '''\n",
        "  \n",
        "  embeddings = pd.read_csv(embeddings_path, sep=';')\n",
        "\n",
        "  return np.array([[np.float64(k) for k in e.split('|')]\n",
        "                   for e in embeddings['vectors']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGvAXnJayWjt"
      },
      "source": [
        "# Environment/Simulator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H00n2XsouByw"
      },
      "source": [
        "class Environment():\n",
        "  def __init__(self, data, embeddings, alpha, gamma, fixed_length):\n",
        "    self.embeddings = embeddings\n",
        "\n",
        "    self.embedded_data = pd.DataFrame()\n",
        "    self.embedded_data['state'] = [np.array([embeddings.get_embedding(item_id) \n",
        "      for item_id in row['state']]) for _, row in data.iterrows()]\n",
        "    self.embedded_data['action'] = [np.array([embeddings.get_embedding(item_id) \n",
        "      for item_id in row['action']]) for _, row in data.iterrows()]\n",
        "    self.embedded_data['reward'] = data['reward']\n",
        "\n",
        "    self.alpha = alpha ## α (alpha) in Equation (1)\n",
        "    self.gamma = gamma ## Γ (Gamma) in Equation (4)\n",
        "    self.fixed_length = fixed_length\n",
        "    self.current_state = self.reset()\n",
        "    self.groups = self.get_groups()\n",
        "\n",
        "  def reset(self):\n",
        "    self.init_state = self.embedded_data['state'].sample(1).values[0]\n",
        "    return self.init_state\n",
        "\n",
        "  def step(self, actions):\n",
        "    '''\n",
        "    Compute reward and update state.\n",
        "    Args:\n",
        "      actions: embedded chosen items.\n",
        "    Returns:\n",
        "      cumulated_reward: overall reward.\n",
        "      current_state: updated state.\n",
        "    '''\n",
        "\n",
        "    ## '18: Compute overall reward r_t according to Equation (4)'\n",
        "    simulated_rewards, cumulated_reward = self.simulate_rewards(self.current_state.reshape((1, -1)), actions.reshape((1, -1)))\n",
        "\n",
        "    ## '11: Set s_t+1 = s_t' <=> self.current_state = self.current_state\n",
        "\n",
        "    for k in range(len(simulated_rewards)): ## '12: for k = 1, K do'\n",
        "      if simulated_rewards[k] > 0: ## '13: if r_t^k > 0 then'\n",
        "        ## '14: Add a_t^k to the end of s_t+1'\n",
        "        self.current_state = np.append(self.current_state, [actions[k]], axis=0)\n",
        "        if self.fixed_length: ## '15: Remove the first item of s_t+1'\n",
        "          self.current_state = np.delete(self.current_state, 0, axis=0)\n",
        "\n",
        "    return cumulated_reward, self.current_state\n",
        "\n",
        "  def get_groups(self):\n",
        "    ''' Calculate average state/action value for each group. Equation (3). '''\n",
        "\n",
        "    groups = []\n",
        "    for rewards, group in self.embedded_data.groupby(['reward']):\n",
        "      size = group.shape[0]\n",
        "      states = np.array(list(group['state'].values))\n",
        "      actions = np.array(list(group['action'].values))\n",
        "      groups.append({\n",
        "        'size': size, ## N_x in article\n",
        "        'rewards': rewards, ## U_x in article (combination of rewards)\n",
        "        'average state': (np.sum(states / np.linalg.norm(states, 2, axis=1)[:, np.newaxis], axis=0) / size).reshape((1, -1)), ## s_x^-\n",
        "        'average action': (np.sum(actions / np.linalg.norm(actions, 2, axis=1)[:, np.newaxis], axis=0) / size).reshape((1, -1)) ## a_x^-\n",
        "      })\n",
        "    return groups\n",
        "\n",
        "  def simulate_rewards(self, current_state, chosen_actions, reward_type='grouped cosine'):\n",
        "    '''\n",
        "    Calculate simulated rewards.\n",
        "    Args:\n",
        "      current_state: history, list of embedded items.\n",
        "      chosen_actions: embedded chosen items.\n",
        "      reward_type: from ['normal', 'grouped average', 'grouped cosine'].\n",
        "    Returns:\n",
        "      returned_rewards: most probable rewards.\n",
        "      cumulated_reward: probability weighted rewards.\n",
        "    '''\n",
        "\n",
        "    ## Equation (1)\n",
        "    def cosine_state_action(s_t, a_t, s_i, a_i):\n",
        "      cosine_state = np.dot(s_t, s_i.T) / (np.linalg.norm(s_t, 2) * np.linalg.norm(s_i, 2))\n",
        "      cosine_action = np.dot(a_t, a_i.T) / (np.linalg.norm(a_t, 2) * np.linalg.norm(a_i, 2))\n",
        "      return (self.alpha * cosine_state + (1 - self.alpha) * cosine_action).reshape((1,))\n",
        "\n",
        "    if reward_type == 'normal':\n",
        "      ## Calculate simulated reward in normal way: Equation (2)\n",
        "      probabilities = [cosine_state_action(current_state, chosen_actions, row['state'], row['action'])\n",
        "        for _, row in self.embedded_data.iterrows()]\n",
        "    elif reward_type == 'grouped average':\n",
        "      ## Calculate simulated reward by grouped average: Equation (3)\n",
        "      probabilities = np.array([g['size'] for g in self.groups]) *\\\n",
        "        [(self.alpha * (np.dot(current_state, g['average state'].T) / np.linalg.norm(current_state, 2))\\\n",
        "        + (1 - self.alpha) * (np.dot(chosen_actions, g['average action'].T) / np.linalg.norm(chosen_actions, 2)))\n",
        "        for g in self.groups]\n",
        "    elif reward_type == 'grouped cosine':\n",
        "      ## Calculate simulated reward by grouped cosine: Equations (1) and (3)\n",
        "      probabilities = [cosine_state_action(current_state, chosen_actions, g['average state'], g['average action'])\n",
        "        for g in self.groups]\n",
        "\n",
        "    ## Normalize (sum to 1)\n",
        "    probabilities = np.array(probabilities) / sum(probabilities)\n",
        "\n",
        "    ## Get most probable rewards\n",
        "    if reward_type == 'normal':\n",
        "      returned_rewards = self.embedded_data.iloc[np.argmax(probabilities)]['reward']\n",
        "    elif reward_type in ['grouped average', 'grouped cosine']:\n",
        "      returned_rewards = self.groups[np.argmax(probabilities)]['rewards']\n",
        "\n",
        "    ## Equation (4)\n",
        "    def overall_reward(rewards, gamma):\n",
        "      return np.sum([gamma**k * reward for k, reward in enumerate(rewards)])\n",
        "\n",
        "    if reward_type in ['normal', 'grouped average']:\n",
        "      ## Get cumulated reward: Equation (4)\n",
        "      cumulated_reward = overall_reward(returned_rewards, self.gamma)\n",
        "    elif reward_type == 'grouped cosine':\n",
        "      ## Get probability weighted cumulated reward\n",
        "      cumulated_reward = np.sum([p * overall_reward(g['rewards'], self.gamma)\n",
        "        for p, g in zip(probabilities, self.groups)])\n",
        "\n",
        "    return returned_rewards, cumulated_reward"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-rEdckqygGY"
      },
      "source": [
        "# Actor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YK3aSNaTouH"
      },
      "source": [
        "class Actor():\n",
        "  ''' Policy function approximator. '''\n",
        "  \n",
        "  def __init__(self, sess, state_space_size, action_space_size, batch_size, ra_length, history_length, embedding_size, tau, learning_rate, scope='actor'):\n",
        "    self.sess = sess\n",
        "    self.state_space_size = state_space_size\n",
        "    self.action_space_size = action_space_size\n",
        "    self.batch_size = batch_size\n",
        "    self.ra_length = ra_length\n",
        "    self.history_length = history_length\n",
        "    self.embedding_size = embedding_size\n",
        "    self.tau = tau\n",
        "    self.learning_rate = learning_rate\n",
        "    self.scope = scope\n",
        "\n",
        "    with tf.variable_scope(self.scope):\n",
        "      ## Build Actor network\n",
        "      self.action_weights, self.state, self.sequence_length = self._build_net('estimator_actor')\n",
        "      self.network_params = tf.trainable_variables()\n",
        "\n",
        "      ## Build target Actor network\n",
        "      self.target_action_weights, self.target_state, self.target_sequence_length = self._build_net('target_actor')\n",
        "      self.target_network_params = tf.trainable_variables()[len(self.network_params):] # TODO: why sublist [len(x):]? Maybe because its equal to network_params + target_network_params\n",
        "\n",
        "      ## Initialize target network weights with network weights (θ^π′ ← θ^π)\n",
        "      self.init_target_network_params = [self.target_network_params[i].assign(self.network_params[i])\n",
        "        for i in range(len(self.target_network_params))]\n",
        "        \n",
        "      ## Update target network weights (θ^π′ ← τθ^π + (1 − τ)θ^π′)\n",
        "      self.update_target_network_params = [self.target_network_params[i].assign(\n",
        "        tf.multiply(self.tau, self.network_params[i]) +\n",
        "        tf.multiply(1 - self.tau, self.target_network_params[i]))\n",
        "        for i in range(len(self.target_network_params))]\n",
        "\n",
        "      ## Gradient computation from Critic's action_gradients\n",
        "      self.action_gradients = tf.placeholder(tf.float32, [None, self.action_space_size])\n",
        "      gradients = tf.gradients(tf.reshape(self.action_weights, [self.batch_size, self.action_space_size], name='42222222222'),\n",
        "                               self.network_params,\n",
        "                               self.action_gradients)\n",
        "      params_gradients = list(map(lambda x: tf.div(x, self.batch_size * self.action_space_size), gradients))\n",
        "      \n",
        "      ## Compute ∇_a.Q(s, a|θ^µ).∇_θ^π.f_θ^π(s)\n",
        "      self.optimizer = tf.train.AdamOptimizer(self.learning_rate).apply_gradients(\n",
        "          zip(params_gradients, self.network_params))\n",
        "\n",
        "  def _build_net(self, scope):\n",
        "    ''' Build the (target) Actor network. '''\n",
        "\n",
        "    def gather_last_output(data, seq_lens):\n",
        "      def cli_value(x, v):\n",
        "        y = tf.constant(v, shape=x.get_shape(), dtype=tf.int64)\n",
        "        x = tf.cast(x, tf.int64)\n",
        "        return tf.where(tf.greater(x, y), x, y)\n",
        "\n",
        "      batch_range = tf.range(tf.cast(tf.shape(data)[0], dtype=tf.int64), dtype=tf.int64)\n",
        "      tmp_end = tf.map_fn(lambda x: cli_value(x, 0), seq_lens - 1, dtype=tf.int64)\n",
        "      indices = tf.stack([batch_range, tmp_end], axis=1)\n",
        "      return tf.gather_nd(data, indices)\n",
        "\n",
        "    with tf.variable_scope(scope):\n",
        "      ## Inputs: current state, sequence_length\n",
        "      ## Outputs: action weights to compute the score Equation (6)\n",
        "      state = tf.placeholder(tf.float32, [None, self.state_space_size], 'state')\n",
        "      state_ = tf.reshape(state, [-1, self.history_length, self.embedding_size])\n",
        "      sequence_length = tf.placeholder(tf.int32, [None], 'sequence_length')\n",
        "      cell = tf.nn.rnn_cell.GRUCell(self.embedding_size,\n",
        "                                    activation=tf.nn.relu,\n",
        "                                    kernel_initializer=tf.initializers.random_normal(),\n",
        "                                    bias_initializer=tf.zeros_initializer())\n",
        "      outputs, _ = tf.nn.dynamic_rnn(cell, state_, dtype=tf.float32, sequence_length=sequence_length)\n",
        "      last_output = gather_last_output(outputs, sequence_length) # TODO: replace by h\n",
        "      x = tf.keras.layers.Dense(self.ra_length * self.embedding_size)(last_output)\n",
        "      action_weights = tf.reshape(x, [-1, self.ra_length, self.embedding_size])\n",
        "\n",
        "    return action_weights, state, sequence_length\n",
        "\n",
        "  def train(self, state, sequence_length, action_gradients):\n",
        "    '''  Compute ∇_a.Q(s, a|θ^µ).∇_θ^π.f_θ^π(s). '''\n",
        "    self.sess.run(self.optimizer,\n",
        "                  feed_dict={\n",
        "                      self.state: state,\n",
        "                      self.sequence_length: sequence_length,\n",
        "                      self.action_gradients: action_gradients})\n",
        "\n",
        "  def predict(self, state, sequence_length):\n",
        "    return self.sess.run(self.action_weights,\n",
        "                         feed_dict={\n",
        "                             self.state: state,\n",
        "                             self.sequence_length: sequence_length})\n",
        "\n",
        "  def predict_target(self, state, sequence_length):\n",
        "    return self.sess.run(self.target_action_weights,\n",
        "                         feed_dict={\n",
        "                             self.target_state: state,\n",
        "                             self.target_sequence_length: sequence_length})\n",
        "\n",
        "  def init_target_network(self):\n",
        "    self.sess.run(self.init_target_network_params)\n",
        "\n",
        "  def update_target_network(self):\n",
        "    self.sess.run(self.update_target_network_params)\n",
        "    \n",
        "  def get_recommendation_list(self, ra_length, noisy_state, embeddings, target=False):\n",
        "    '''\n",
        "    Algorithm 2\n",
        "    Args:\n",
        "      ra_length: length of the recommendation list.\n",
        "      noisy_state: current/remembered environment state with noise.\n",
        "      embeddings: Embeddings object.\n",
        "      target: boolean to use Actor's network or target network.\n",
        "    Returns:\n",
        "      Recommendation List: list of embedded items as future actions.\n",
        "    '''\n",
        "\n",
        "    def get_score(weights, embedding, batch_size):\n",
        "      '''\n",
        "      Equation (6)\n",
        "      Args:\n",
        "        weights: w_t^k shape=(embedding_size,).\n",
        "        embedding: e_i shape=(embedding_size,).\n",
        "      Returns:\n",
        "        score of the item i: score_i=w_t^k.e_i^T shape=(1,).\n",
        "      '''\n",
        "      ret = np.dot(weights, embedding.T)\n",
        "      return ret\n",
        "\n",
        "    batch_size = noisy_state.shape[0]\n",
        "\n",
        "    ## '1: Generate w_t = {w_t^1, ..., w_t^K} according to Equation (5)'\n",
        "    method = self.predict_target if target else self.predict\n",
        "    weights = method(noisy_state, [ra_length] * batch_size)\n",
        "\n",
        "    ## '3: Score items in I according to Equation (6)'\n",
        "    scores = np.array([[[get_score(weights[i][k], embedding, batch_size)\n",
        "      for embedding in embeddings.get_embedding_vector()]\n",
        "      for k in range(ra_length)]\n",
        "      for i in range(batch_size)])\n",
        "\n",
        "    ## '8: return a_t'\n",
        "    return np.array([[embeddings.get_embedding(np.argmax(scores[i][k]))\n",
        "      for k in range(ra_length)]\n",
        "      for i in range(batch_size)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVAPvO0Nyyy3"
      },
      "source": [
        "# Critic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jj3yEhnqy0Iy"
      },
      "source": [
        "class Critic():\n",
        "  ''' Value function approximator. '''\n",
        "  \n",
        "  def __init__(self, sess, state_space_size, action_space_size, history_length, embedding_size, tau, learning_rate, scope='critic'):\n",
        "    self.sess = sess\n",
        "    self.state_space_size = state_space_size\n",
        "    self.action_space_size = action_space_size\n",
        "    self.history_length = history_length\n",
        "    self.embedding_size = embedding_size\n",
        "    self.tau = tau\n",
        "    self.learning_rate = learning_rate\n",
        "    self.scope = scope\n",
        "\n",
        "    with tf.variable_scope(self.scope):\n",
        "      ## Build Critic network\n",
        "      self.critic_Q_value, self.state, self.action, self.sequence_length = self._build_net('estimator_critic')\n",
        "      self.network_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='estimator_critic')\n",
        "\n",
        "      ## Build target Critic network\n",
        "      self.target_Q_value, self.target_state, self.target_action, self.target_sequence_length = self._build_net('target_critic')\n",
        "      self.target_network_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='target_critic')\n",
        "\n",
        "      ## Initialize target network weights with network weights (θ^µ′ ← θ^µ)\n",
        "      self.init_target_network_params = [self.target_network_params[i].assign(self.network_params[i])\n",
        "        for i in range(len(self.target_network_params))]\n",
        "\n",
        "      ## Update target network weights (θ^µ′ ← τθ^µ + (1 − τ)θ^µ′)\n",
        "      self.update_target_network_params = [self.target_network_params[i].assign(\n",
        "        tf.multiply(self.tau, self.network_params[i]) +\n",
        "        tf.multiply(1 - self.tau, self.target_network_params[i]))\n",
        "        for i in range(len(self.target_network_params))]\n",
        "\n",
        "      ## Minimize MSE between Critic's and target Critic's outputed Q-values\n",
        "      self.expected_reward = tf.placeholder(tf.float32, [None, 1])\n",
        "      self.loss = tf.reduce_mean(tf.squared_difference(self.expected_reward, self.critic_Q_value))\n",
        "      self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
        "\n",
        "      ## Compute ∇_a.Q(s, a|θ^µ)\n",
        "      self.action_gradients = tf.gradients(self.critic_Q_value, self.action)\n",
        "\n",
        "  def _build_net(self, scope):\n",
        "    ''' Build the (target) Critic network. '''\n",
        "\n",
        "    def gather_last_output(data, seq_lens):\n",
        "      def cli_value(x, v):\n",
        "        y = tf.constant(v, shape=x.get_shape(), dtype=tf.int64)\n",
        "        return tf.where(tf.greater(x, y), x, y)\n",
        "\n",
        "      this_range = tf.range(tf.cast(tf.shape(seq_lens)[0], dtype=tf.int64), dtype=tf.int64)\n",
        "      tmp_end = tf.map_fn(lambda x: cli_value(x, 0), seq_lens - 1, dtype=tf.int64)\n",
        "      indices = tf.stack([this_range, tmp_end], axis=1)\n",
        "      return tf.gather_nd(data, indices)\n",
        "\n",
        "    with tf.variable_scope(scope):\n",
        "      ## Inputs: current state, current action\n",
        "      ## Outputs: predicted Q-value\n",
        "      state = tf.placeholder(tf.float32, [None, self.state_space_size], 'state')\n",
        "      state_ = tf.reshape(state, [-1, self.history_length, self.embedding_size])\n",
        "      action = tf.placeholder(tf.float32, [None, self.action_space_size], 'action')\n",
        "      sequence_length = tf.placeholder(tf.int64, [None], name='critic_sequence_length')\n",
        "      cell = tf.nn.rnn_cell.GRUCell(self.history_length,\n",
        "                                    activation=tf.nn.relu,\n",
        "                                    kernel_initializer=tf.initializers.random_normal(),\n",
        "                                    bias_initializer=tf.zeros_initializer())\n",
        "      predicted_state, _ = tf.nn.dynamic_rnn(cell, state_, dtype=tf.float32, sequence_length=sequence_length)\n",
        "      predicted_state = gather_last_output(predicted_state, sequence_length)\n",
        "\n",
        "      inputs = tf.concat([predicted_state, action], axis=-1)\n",
        "      layer1 = tf.layers.Dense(32, activation=tf.nn.relu)(inputs)\n",
        "      layer2 = tf.layers.Dense(16, activation=tf.nn.relu)(layer1)\n",
        "      critic_Q_value = tf.layers.Dense(1)(layer2)\n",
        "      return critic_Q_value, state, action, sequence_length\n",
        "\n",
        "  def train(self, state, action, sequence_length, expected_reward):\n",
        "    ''' Minimize MSE between expected reward and target Critic's Q-value. '''\n",
        "    return self.sess.run([self.critic_Q_value, self.loss, self.optimizer],\n",
        "                         feed_dict={\n",
        "                             self.state: state,\n",
        "                             self.action: action,\n",
        "                             self.sequence_length: sequence_length,\n",
        "                             self.expected_reward: expected_reward})\n",
        "\n",
        "  def predict(self, state, action, sequence_length):\n",
        "    ''' Returns Critic's predicted Q-value. '''\n",
        "    return self.sess.run(self.critic_Q_value,\n",
        "                         feed_dict={\n",
        "                             self.state: state,\n",
        "                             self.action: action,\n",
        "                             self.sequence_length: sequence_length})\n",
        "\n",
        "  def predict_target(self, state, action, sequence_length):\n",
        "    ''' Returns target Critic's predicted Q-value. '''\n",
        "    return self.sess.run(self.target_Q_value,\n",
        "                         feed_dict={\n",
        "                             self.target_state: state,\n",
        "                             self.target_action: action,\n",
        "                             self.target_sequence_length: sequence_length})\n",
        "\n",
        "  def get_action_gradients(self, state, action, sequence_length):\n",
        "    ''' Returns ∇_a.Q(s, a|θ^µ). '''\n",
        "    return np.array(self.sess.run(self.action_gradients,\n",
        "                         feed_dict={\n",
        "                             self.state: state,\n",
        "                             self.action: action,\n",
        "                             self.sequence_length: sequence_length})[0])\n",
        "\n",
        "  def init_target_network(self):\n",
        "    self.sess.run(self.init_target_network_params)\n",
        "\n",
        "  def update_target_network(self):\n",
        "    self.sess.run(self.update_target_network_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNP3jdofyh7M"
      },
      "source": [
        "# Replay"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvIqtE2YzoUa"
      },
      "source": [
        "class ReplayMemory():\n",
        "  ''' Replay memory D in article. '''\n",
        "  \n",
        "  def __init__(self, buffer_size):\n",
        "    self.buffer_size = buffer_size\n",
        "    ## self.buffer = [[row['state'], row['action'], row['reward'], row['n_state']] for _, row in data.iterrows()][-self.buffer_size:] TODO: empty or not?\n",
        "    self.buffer = []\n",
        "\n",
        "  def add(self, state, action, reward, n_state):\n",
        "    self.buffer.append([state, action, reward, n_state])\n",
        "    if len(self.buffer) > self.buffer_size:\n",
        "      self.buffer.pop(0)\n",
        "\n",
        "  def size(self):\n",
        "    return len(self.buffer)\n",
        "\n",
        "  def sample_batch(self, batch_size):\n",
        "    return random.sample(self.buffer, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x-ekweNfStD"
      },
      "source": [
        "def experience_replay(replay_memory, batch_size, actor, critic, embeddings, ra_length, state_space_size, action_space_size, discount_factor):\n",
        "  '''\n",
        "  Experience replay.\n",
        "  Args:\n",
        "    replay_memory: replay memory D in article.\n",
        "    batch_size: sample size.\n",
        "    actor: Actor network.\n",
        "    critic: Critic network.\n",
        "    embeddings: Embeddings object.\n",
        "    state_space_size: dimension of states.\n",
        "    action_space_size: dimensions of actions.\n",
        "  Returns:\n",
        "    Best Q-value, loss of Critic network for printing/recording purpose.\n",
        "  '''\n",
        "\n",
        "  ## '22: Sample minibatch of N transitions (s, a, r, s′) from D'\n",
        "  samples = replay_memory.sample_batch(batch_size)\n",
        "  states = np.array([s[0] for s in samples])\n",
        "  actions = np.array([s[1] for s in samples])\n",
        "  rewards = np.array([s[2] for s in samples])\n",
        "  n_states = np.array([s[3] for s in samples]).reshape(-1, state_space_size)\n",
        "\n",
        "  ## '23: Generate a′ by target Actor network according to Algorithm 2'\n",
        "  n_actions = actor.get_recommendation_list(ra_length, states, embeddings, target=True).reshape(-1, action_space_size)\n",
        "\n",
        "  ## Calculate predicted Q′(s′, a′|θ^µ′) value\n",
        "  target_Q_value = critic.predict_target(n_states, n_actions, [ra_length] * batch_size)\n",
        "\n",
        "  ## '24: Set y = r + γQ′(s′, a′|θ^µ′)'\n",
        "  expected_rewards = rewards + discount_factor * target_Q_value\n",
        "  \n",
        "  ## '25: Update Critic by minimizing (y − Q(s, a|θ^µ))²'\n",
        "  critic_Q_value, critic_loss, _ = critic.train(states, actions, [ra_length] * batch_size, expected_rewards)\n",
        "  \n",
        "  ## '26: Update the Actor using the sampled policy gradient'\n",
        "  action_gradients = critic.get_action_gradients(states, n_actions, [ra_length] * batch_size)\n",
        "  actor.train(states, [ra_length] * batch_size, action_gradients)\n",
        "\n",
        "  ## '27: Update the Critic target networks'\n",
        "  critic.update_target_network()\n",
        "\n",
        "  ## '28: Update the Actor target network'\n",
        "  actor.update_target_network()\n",
        "\n",
        "  return np.amax(critic_Q_value), critic_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzYw4cAhzYDF"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRDXsrsMy69k"
      },
      "source": [
        "class OrnsteinUhlenbeckNoise:\n",
        "  ''' Noise for Actor predictions. '''\n",
        "  def __init__(self, action_space_size, mu=0, theta=0.5, sigma=0.2):\n",
        "    self.action_space_size = action_space_size\n",
        "    self.mu = mu\n",
        "    self.theta = theta\n",
        "    self.sigma = sigma\n",
        "    self.state = np.ones(self.action_space_size) * self.mu\n",
        "\n",
        "  def get(self):\n",
        "    self.state += self.theta * (self.mu - self.state) + self.sigma * np.random.rand(self.action_space_size)\n",
        "    return self.state\n",
        "\n",
        "def train(sess, environment, actor, critic, embeddings, history_length, ra_length, buffer_size, batch_size, discount_factor, nb_episodes, filename_summary):\n",
        "  ''' Algorithm 3 in article. '''\n",
        "\n",
        "  ## Set up summary operators\n",
        "  def build_summaries():\n",
        "    episode_reward = tf.Variable(0.)\n",
        "    tf.summary.scalar('reward', episode_reward)\n",
        "    episode_max_Q = tf.Variable(0.)\n",
        "    tf.summary.scalar('max_Q_value', episode_max_Q)\n",
        "    critic_loss = tf.Variable(0.)\n",
        "    tf.summary.scalar('critic_loss', critic_loss)\n",
        "\n",
        "    summary_vars = [episode_reward, episode_max_Q, critic_loss]\n",
        "    summary_ops = tf.summary.merge_all()\n",
        "    return summary_ops, summary_vars\n",
        "\n",
        "  summary_ops, summary_vars = build_summaries()\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  writer = tf.summary.FileWriter(filename_summary, sess.graph)\n",
        "\n",
        "  ## '2: Initialize target network f′ and Q′'\n",
        "  actor.init_target_network()\n",
        "  critic.init_target_network()\n",
        "\n",
        "  ## '3: Initialize the capacity of replay memory D'\n",
        "  replay_memory = ReplayMemory(buffer_size) # Memory D in article\n",
        "  replay = False\n",
        "\n",
        "\n",
        "  start_time = time.time()\n",
        "  for i_session in range(nb_episodes): # '4: for session = 1, M do'\n",
        "    session_reward = 0\n",
        "    session_Q_value = 0\n",
        "    session_critic_loss = 0\n",
        "\n",
        "    ## '5: Reset the item space I' is useless because unchanged.\n",
        "\n",
        "    states = environment.reset() # '6: Initialize state s_0 from previous sessions'\n",
        "    \n",
        "    if (i_session + 1) % 10 == 0: # Update average parameters every 10 episodes\n",
        "      environment.groups = environment.get_groups()\n",
        "      \n",
        "    exploration_noise = OrnsteinUhlenbeckNoise(history_length * embeddings.size())\n",
        "\n",
        "    for t in range(nb_rounds): # '7: for t = 1, T do'\n",
        "      ## '8: Stage 1: Transition Generating Stage'\n",
        "\n",
        "      ## '9: Select an action a_t = {a_t^1, ..., a_t^K} according to Algorithm 2'\n",
        "      actions = actor.get_recommendation_list(\n",
        "          ra_length,\n",
        "          states.reshape(1, -1), # TODO + exploration_noise.get().reshape(1, -1),\n",
        "          embeddings).reshape(ra_length, embeddings.size())\n",
        "\n",
        "      ## '10: Execute action a_t and observe the reward list {r_t^1, ..., r_t^K} for each item in a_t'\n",
        "      rewards, next_states = environment.step(actions)\n",
        "\n",
        "      ## '19: Store transition (s_t, a_t, r_t, s_t+1) in D'\n",
        "      replay_memory.add(states.reshape(history_length * embeddings.size()),\n",
        "                        actions.reshape(ra_length * embeddings.size()),\n",
        "                        [rewards],\n",
        "                        next_states.reshape(history_length * embeddings.size()))\n",
        "\n",
        "      states = next_states ## '20: Set s_t = s_t+1'\n",
        "\n",
        "      session_reward += rewards\n",
        "      \n",
        "      ## '21: Stage 2: Parameter Updating Stage'\n",
        "      if replay_memory.size() >= batch_size: ## Experience replay\n",
        "        replay = True\n",
        "        replay_Q_value, critic_loss = experience_replay(replay_memory, batch_size,\n",
        "          actor, critic, embeddings, ra_length, history_length * embeddings.size(),\n",
        "          ra_length * embeddings.size(), discount_factor)\n",
        "        session_Q_value += replay_Q_value\n",
        "        session_critic_loss += critic_loss\n",
        "\n",
        "      summary_str = sess.run(summary_ops,\n",
        "                             feed_dict={summary_vars[0]: session_reward,\n",
        "                                        summary_vars[1]: session_Q_value,\n",
        "                                        summary_vars[2]: session_critic_loss})\n",
        "      \n",
        "      writer.add_summary(summary_str, i_session)\n",
        "\n",
        "      '''\n",
        "      print(state_to_items(embeddings.embed(data['state'][0]), actor, ra_length, embeddings),\n",
        "            state_to_items(embeddings.embed(data['state'][0]), actor, ra_length, embeddings, True))\n",
        "      '''\n",
        "\n",
        "    str_loss = str('Loss=%0.4f' % session_critic_loss)\n",
        "    print(('Episode %d/%d Reward=%d Time=%ds ' + (str_loss if replay else 'No replay')) % (i_session + 1, nb_episodes, session_reward, time.time() - start_time))\n",
        "    start_time = time.time()\n",
        "\n",
        "  writer.close()\n",
        "  tf.train.Saver().save(sess, 'models.h5', write_meta_graph=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cx_5zk2hll5e"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8vv6bRi5_ro"
      },
      "source": [
        "## Hyperparameters\n",
        "history_length = 12 ## N in article\n",
        "ra_length = 4 ## K in article\n",
        "discount_factor = 0.99 ## Gamma in Bellman equation\n",
        "actor_lr = 0.0001\n",
        "critic_lr = 0.001\n",
        "tau = 0.001 ## τ in Algorithm 3\n",
        "batch_size = 64\n",
        "nb_episodes = 10\n",
        "nb_rounds = 50\n",
        "filename_summary = 'summary.txt'\n",
        "alpha = 0.5 ## α (alpha) in Equation (1)\n",
        "gamma = 0.9 ## Γ (Gamma) in Equation (4)\n",
        "buffer_size = 1000000 ## Size of replay memory D in article\n",
        "fixed_length = True ## Fixed memory length\n",
        "\n",
        "dg = DataGenerator('ml-100k/u.data', 'ml-100k/u.item')\n",
        "dg.gen_train_test(0.8, seed=42)\n",
        "\n",
        "dg.write_csv('train.csv', dg.train, nb_states=[history_length], nb_actions=[ra_length])\n",
        "dg.write_csv('test.csv', dg.test, nb_states=[history_length], nb_actions=[ra_length])\n",
        "\n",
        "data = read_file('train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-aa79rvlpWH"
      },
      "source": [
        "## Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezsuxZbllgDg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5d57b875-0517-4de5-e1ea-a829a45e5821"
      },
      "source": [
        "## Generate embeddings\n",
        "eg = EmbeddingsGenerator(dg.user_train, pd.read_csv('ml-100k/u.data', sep='\\t', names=['userId', 'itemId', 'rating', 'timestamp']))\n",
        "eg.train(nb_epochs=300)\n",
        "train_loss, train_accuracy = eg.test(dg.user_train)\n",
        "print('Train set: Loss=%.4f ; Accuracy=%.1f%%' % (train_loss, train_accuracy * 100))\n",
        "test_loss, test_accuracy = eg.test(dg.user_test)\n",
        "print('Test set: Loss=%.4f ; Accuracy=%.1f%%' % (test_loss, test_accuracy * 100))\n",
        "eg.save_embeddings('embeddings.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "4992/5000 [============================>.] - ETA: 0s - loss: 6.9002 - acc: 0.0118"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5000/5000 [==============================] - 3s 658us/sample - loss: 6.8989 - acc: 0.0118 - val_loss: 6.5340 - val_acc: 0.0116\n",
            "2/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 350us/sample - loss: 6.4783 - acc: 0.0110 - val_loss: 6.3137 - val_acc: 0.0120\n",
            "3/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 343us/sample - loss: 6.3133 - acc: 0.0154 - val_loss: 6.2253 - val_acc: 0.0154\n",
            "4/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 338us/sample - loss: 6.2209 - acc: 0.0176 - val_loss: 6.1056 - val_acc: 0.0244\n",
            "5/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 349us/sample - loss: 6.1476 - acc: 0.0162 - val_loss: 6.1173 - val_acc: 0.0190\n",
            "6/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 348us/sample - loss: 6.0809 - acc: 0.0186 - val_loss: 6.0504 - val_acc: 0.0216\n",
            "7/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 348us/sample - loss: 6.0863 - acc: 0.0222 - val_loss: 6.0039 - val_acc: 0.0252\n",
            "8/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 353us/sample - loss: 6.0529 - acc: 0.0240 - val_loss: 5.9354 - val_acc: 0.0260\n",
            "9/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 344us/sample - loss: 6.0089 - acc: 0.0250 - val_loss: 5.9713 - val_acc: 0.0210\n",
            "10/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 345us/sample - loss: 6.0174 - acc: 0.0238 - val_loss: 5.8748 - val_acc: 0.0294\n",
            "11/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 356us/sample - loss: 5.9410 - acc: 0.0246 - val_loss: 5.8605 - val_acc: 0.0348\n",
            "12/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 354us/sample - loss: 5.9259 - acc: 0.0280 - val_loss: 5.8345 - val_acc: 0.0322\n",
            "13/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 351us/sample - loss: 5.8654 - acc: 0.0296 - val_loss: 5.8213 - val_acc: 0.0324\n",
            "14/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 346us/sample - loss: 5.8845 - acc: 0.0284 - val_loss: 5.7878 - val_acc: 0.0366\n",
            "15/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 348us/sample - loss: 5.8766 - acc: 0.0316 - val_loss: 5.8214 - val_acc: 0.0372\n",
            "16/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 347us/sample - loss: 5.8382 - acc: 0.0354 - val_loss: 5.7533 - val_acc: 0.0408\n",
            "17/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 344us/sample - loss: 5.7912 - acc: 0.0364 - val_loss: 5.7331 - val_acc: 0.0442\n",
            "18/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 348us/sample - loss: 5.7924 - acc: 0.0388 - val_loss: 5.7178 - val_acc: 0.0452\n",
            "19/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 345us/sample - loss: 5.7654 - acc: 0.0400 - val_loss: 5.6889 - val_acc: 0.0500\n",
            "20/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 346us/sample - loss: 5.7896 - acc: 0.0394 - val_loss: 5.6692 - val_acc: 0.0572\n",
            "21/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 340us/sample - loss: 5.6972 - acc: 0.0474 - val_loss: 5.6339 - val_acc: 0.0590\n",
            "22/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 348us/sample - loss: 5.7488 - acc: 0.0512 - val_loss: 5.6342 - val_acc: 0.0598\n",
            "23/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 348us/sample - loss: 5.6944 - acc: 0.0528 - val_loss: 5.5977 - val_acc: 0.0658\n",
            "24/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 354us/sample - loss: 5.6228 - acc: 0.0596 - val_loss: 5.5618 - val_acc: 0.0672\n",
            "25/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 360us/sample - loss: 5.6101 - acc: 0.0598 - val_loss: 5.4871 - val_acc: 0.0796\n",
            "26/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 340us/sample - loss: 5.5966 - acc: 0.0610 - val_loss: 5.5286 - val_acc: 0.0762\n",
            "27/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 349us/sample - loss: 5.5855 - acc: 0.0708 - val_loss: 5.4887 - val_acc: 0.0840\n",
            "28/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 349us/sample - loss: 5.5252 - acc: 0.0686 - val_loss: 5.4683 - val_acc: 0.0790\n",
            "29/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 360us/sample - loss: 5.5347 - acc: 0.0722 - val_loss: 5.4275 - val_acc: 0.0920\n",
            "30/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 336us/sample - loss: 5.5072 - acc: 0.0742 - val_loss: 5.3897 - val_acc: 0.0948\n",
            "31/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 347us/sample - loss: 5.4438 - acc: 0.0838 - val_loss: 5.3905 - val_acc: 0.0950\n",
            "32/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 360us/sample - loss: 5.4453 - acc: 0.0866 - val_loss: 5.3225 - val_acc: 0.0938\n",
            "33/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 352us/sample - loss: 5.4050 - acc: 0.0844 - val_loss: 5.3057 - val_acc: 0.0948\n",
            "34/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 357us/sample - loss: 5.3297 - acc: 0.0926 - val_loss: 5.3014 - val_acc: 0.0974\n",
            "35/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 357us/sample - loss: 5.3410 - acc: 0.0990 - val_loss: 5.2439 - val_acc: 0.1122\n",
            "36/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 362us/sample - loss: 5.3260 - acc: 0.1022 - val_loss: 5.2359 - val_acc: 0.1202\n",
            "37/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 356us/sample - loss: 5.2970 - acc: 0.1078 - val_loss: 5.1744 - val_acc: 0.1290\n",
            "38/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 356us/sample - loss: 5.2823 - acc: 0.1144 - val_loss: 5.1296 - val_acc: 0.1394\n",
            "39/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 351us/sample - loss: 5.1910 - acc: 0.1190 - val_loss: 5.1122 - val_acc: 0.1332\n",
            "40/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 349us/sample - loss: 5.1924 - acc: 0.1184 - val_loss: 5.0499 - val_acc: 0.1460\n",
            "41/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 355us/sample - loss: 5.1850 - acc: 0.1160 - val_loss: 4.9686 - val_acc: 0.1538\n",
            "42/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 349us/sample - loss: 5.1826 - acc: 0.1226 - val_loss: 4.9680 - val_acc: 0.1502\n",
            "43/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 354us/sample - loss: 5.0915 - acc: 0.1284 - val_loss: 4.9278 - val_acc: 0.1578\n",
            "44/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 358us/sample - loss: 5.0358 - acc: 0.1406 - val_loss: 4.9212 - val_acc: 0.1612\n",
            "45/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 346us/sample - loss: 5.0218 - acc: 0.1380 - val_loss: 4.8971 - val_acc: 0.1768\n",
            "46/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 345us/sample - loss: 4.9531 - acc: 0.1546 - val_loss: 4.8655 - val_acc: 0.1904\n",
            "47/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 348us/sample - loss: 5.0062 - acc: 0.1476 - val_loss: 4.7971 - val_acc: 0.1894\n",
            "48/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 358us/sample - loss: 4.9294 - acc: 0.1526 - val_loss: 4.7477 - val_acc: 0.1956\n",
            "49/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 344us/sample - loss: 4.9125 - acc: 0.1632 - val_loss: 4.7873 - val_acc: 0.1912\n",
            "50/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 356us/sample - loss: 4.8164 - acc: 0.1716 - val_loss: 4.6328 - val_acc: 0.2174\n",
            "51/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 353us/sample - loss: 4.7985 - acc: 0.1774 - val_loss: 4.6241 - val_acc: 0.2182\n",
            "52/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 354us/sample - loss: 4.7861 - acc: 0.1828 - val_loss: 4.6253 - val_acc: 0.2288\n",
            "53/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 364us/sample - loss: 4.7426 - acc: 0.1878 - val_loss: 4.5794 - val_acc: 0.2270\n",
            "54/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 348us/sample - loss: 4.6849 - acc: 0.1978 - val_loss: 4.5148 - val_acc: 0.2376\n",
            "55/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 363us/sample - loss: 4.6704 - acc: 0.2016 - val_loss: 4.5389 - val_acc: 0.2372\n",
            "56/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 359us/sample - loss: 4.5714 - acc: 0.2064 - val_loss: 4.4065 - val_acc: 0.2718\n",
            "57/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 352us/sample - loss: 4.5629 - acc: 0.2150 - val_loss: 4.3583 - val_acc: 0.2814\n",
            "58/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 354us/sample - loss: 4.5429 - acc: 0.2176 - val_loss: 4.3733 - val_acc: 0.2612\n",
            "59/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 364us/sample - loss: 4.5199 - acc: 0.2224 - val_loss: 4.3054 - val_acc: 0.2804\n",
            "60/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 364us/sample - loss: 4.5034 - acc: 0.2234 - val_loss: 4.2713 - val_acc: 0.2884\n",
            "61/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 355us/sample - loss: 4.3842 - acc: 0.2444 - val_loss: 4.2418 - val_acc: 0.3012\n",
            "62/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 349us/sample - loss: 4.3562 - acc: 0.2474 - val_loss: 4.1911 - val_acc: 0.3030\n",
            "63/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 356us/sample - loss: 4.3088 - acc: 0.2582 - val_loss: 4.0958 - val_acc: 0.3174\n",
            "64/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 354us/sample - loss: 4.3176 - acc: 0.2638 - val_loss: 4.0650 - val_acc: 0.3324\n",
            "65/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 349us/sample - loss: 4.2958 - acc: 0.2716 - val_loss: 4.0821 - val_acc: 0.3268\n",
            "66/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 359us/sample - loss: 4.2422 - acc: 0.2700 - val_loss: 3.9740 - val_acc: 0.3414\n",
            "67/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 351us/sample - loss: 4.1129 - acc: 0.2876 - val_loss: 3.9454 - val_acc: 0.3526\n",
            "68/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 364us/sample - loss: 4.1332 - acc: 0.2830 - val_loss: 3.8736 - val_acc: 0.3626\n",
            "69/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 349us/sample - loss: 4.0792 - acc: 0.2994 - val_loss: 3.8311 - val_acc: 0.3780\n",
            "70/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 338us/sample - loss: 3.9954 - acc: 0.3092 - val_loss: 3.8026 - val_acc: 0.3774\n",
            "71/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 335us/sample - loss: 3.9360 - acc: 0.3200 - val_loss: 3.7264 - val_acc: 0.3946\n",
            "72/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 349us/sample - loss: 3.9833 - acc: 0.3082 - val_loss: 3.6617 - val_acc: 0.4170\n",
            "73/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 343us/sample - loss: 3.8496 - acc: 0.3374 - val_loss: 3.6876 - val_acc: 0.4018\n",
            "74/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 347us/sample - loss: 3.9076 - acc: 0.3300 - val_loss: 3.5978 - val_acc: 0.4148\n",
            "75/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 348us/sample - loss: 3.8676 - acc: 0.3278 - val_loss: 3.4996 - val_acc: 0.4316\n",
            "76/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 357us/sample - loss: 3.7848 - acc: 0.3388 - val_loss: 3.5076 - val_acc: 0.4376\n",
            "77/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 342us/sample - loss: 3.7740 - acc: 0.3496 - val_loss: 3.4828 - val_acc: 0.4340\n",
            "78/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 345us/sample - loss: 3.6510 - acc: 0.3732 - val_loss: 3.4556 - val_acc: 0.4482\n",
            "79/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 352us/sample - loss: 3.6220 - acc: 0.3792 - val_loss: 3.3537 - val_acc: 0.4574\n",
            "80/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 340us/sample - loss: 3.6140 - acc: 0.3774 - val_loss: 3.3738 - val_acc: 0.4726\n",
            "81/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 348us/sample - loss: 3.5387 - acc: 0.3870 - val_loss: 3.2771 - val_acc: 0.4742\n",
            "82/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 351us/sample - loss: 3.4991 - acc: 0.3926 - val_loss: 3.2430 - val_acc: 0.4978\n",
            "83/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 333us/sample - loss: 3.4801 - acc: 0.4072 - val_loss: 3.1823 - val_acc: 0.5078\n",
            "84/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 340us/sample - loss: 3.4160 - acc: 0.4202 - val_loss: 3.1665 - val_acc: 0.5084\n",
            "85/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 345us/sample - loss: 3.3954 - acc: 0.4174 - val_loss: 3.1691 - val_acc: 0.5076\n",
            "86/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 349us/sample - loss: 3.3292 - acc: 0.4316 - val_loss: 3.0495 - val_acc: 0.5220\n",
            "87/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 352us/sample - loss: 3.2788 - acc: 0.4338 - val_loss: 3.0218 - val_acc: 0.5436\n",
            "88/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 351us/sample - loss: 3.2257 - acc: 0.4462 - val_loss: 2.9657 - val_acc: 0.5496\n",
            "89/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 344us/sample - loss: 3.1815 - acc: 0.4566 - val_loss: 2.9481 - val_acc: 0.5548\n",
            "90/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 354us/sample - loss: 3.1757 - acc: 0.4600 - val_loss: 2.8208 - val_acc: 0.5766\n",
            "91/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 345us/sample - loss: 3.0696 - acc: 0.4772 - val_loss: 2.8096 - val_acc: 0.5748\n",
            "92/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 357us/sample - loss: 2.9937 - acc: 0.4906 - val_loss: 2.7482 - val_acc: 0.5966\n",
            "93/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 354us/sample - loss: 2.9789 - acc: 0.4892 - val_loss: 2.6879 - val_acc: 0.6030\n",
            "94/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 349us/sample - loss: 2.9515 - acc: 0.5074 - val_loss: 2.7227 - val_acc: 0.5864\n",
            "95/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 347us/sample - loss: 2.8718 - acc: 0.5204 - val_loss: 2.5685 - val_acc: 0.6214\n",
            "96/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 351us/sample - loss: 2.8538 - acc: 0.5166 - val_loss: 2.6236 - val_acc: 0.6184\n",
            "97/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 344us/sample - loss: 2.8306 - acc: 0.5256 - val_loss: 2.5809 - val_acc: 0.6176\n",
            "98/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 345us/sample - loss: 2.6781 - acc: 0.5516 - val_loss: 2.5033 - val_acc: 0.6224\n",
            "99/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 345us/sample - loss: 2.6618 - acc: 0.5502 - val_loss: 2.4232 - val_acc: 0.6528\n",
            "100/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 355us/sample - loss: 2.6598 - acc: 0.5500 - val_loss: 2.4008 - val_acc: 0.6512\n",
            "101/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 352us/sample - loss: 2.6252 - acc: 0.5620 - val_loss: 2.3625 - val_acc: 0.6568\n",
            "102/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 358us/sample - loss: 2.6003 - acc: 0.5716 - val_loss: 2.2861 - val_acc: 0.6746\n",
            "103/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 355us/sample - loss: 2.5534 - acc: 0.5764 - val_loss: 2.2999 - val_acc: 0.6670\n",
            "104/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 359us/sample - loss: 2.5506 - acc: 0.5806 - val_loss: 2.2210 - val_acc: 0.6866\n",
            "105/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 341us/sample - loss: 2.4627 - acc: 0.5958 - val_loss: 2.1638 - val_acc: 0.7024\n",
            "106/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 346us/sample - loss: 2.3991 - acc: 0.6084 - val_loss: 2.1916 - val_acc: 0.6838\n",
            "107/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 350us/sample - loss: 2.3429 - acc: 0.6162 - val_loss: 2.0830 - val_acc: 0.7154\n",
            "108/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 350us/sample - loss: 2.3109 - acc: 0.6264 - val_loss: 2.0568 - val_acc: 0.7088\n",
            "109/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 346us/sample - loss: 2.2999 - acc: 0.6248 - val_loss: 2.0397 - val_acc: 0.7282\n",
            "110/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 356us/sample - loss: 2.2642 - acc: 0.6284 - val_loss: 1.9717 - val_acc: 0.7324\n",
            "111/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 359us/sample - loss: 2.1482 - acc: 0.6582 - val_loss: 1.8892 - val_acc: 0.7468\n",
            "112/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 351us/sample - loss: 2.2132 - acc: 0.6416 - val_loss: 1.8647 - val_acc: 0.7458\n",
            "113/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 357us/sample - loss: 2.1226 - acc: 0.6588 - val_loss: 1.8348 - val_acc: 0.7562\n",
            "114/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 353us/sample - loss: 2.0033 - acc: 0.6786 - val_loss: 1.7968 - val_acc: 0.7596\n",
            "115/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 355us/sample - loss: 2.0419 - acc: 0.6730 - val_loss: 1.7801 - val_acc: 0.7638\n",
            "116/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 348us/sample - loss: 2.0072 - acc: 0.6814 - val_loss: 1.7274 - val_acc: 0.7642\n",
            "117/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 353us/sample - loss: 1.9340 - acc: 0.6936 - val_loss: 1.6608 - val_acc: 0.7782\n",
            "118/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 354us/sample - loss: 1.9436 - acc: 0.6930 - val_loss: 1.6747 - val_acc: 0.7814\n",
            "119/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 351us/sample - loss: 1.8877 - acc: 0.7052 - val_loss: 1.6534 - val_acc: 0.7856\n",
            "120/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 348us/sample - loss: 1.8540 - acc: 0.6986 - val_loss: 1.5791 - val_acc: 0.7874\n",
            "121/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 349us/sample - loss: 1.8080 - acc: 0.7236 - val_loss: 1.5949 - val_acc: 0.7812\n",
            "122/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 362us/sample - loss: 1.8190 - acc: 0.7164 - val_loss: 1.5068 - val_acc: 0.7990\n",
            "123/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 357us/sample - loss: 1.7566 - acc: 0.7200 - val_loss: 1.4777 - val_acc: 0.8080\n",
            "124/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 353us/sample - loss: 1.7288 - acc: 0.7362 - val_loss: 1.4467 - val_acc: 0.8146\n",
            "125/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 358us/sample - loss: 1.6841 - acc: 0.7404 - val_loss: 1.4263 - val_acc: 0.8210\n",
            "126/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 354us/sample - loss: 1.5997 - acc: 0.7566 - val_loss: 1.4659 - val_acc: 0.8102\n",
            "127/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 357us/sample - loss: 1.5525 - acc: 0.7634 - val_loss: 1.3673 - val_acc: 0.8234\n",
            "128/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 352us/sample - loss: 1.5641 - acc: 0.7602 - val_loss: 1.3503 - val_acc: 0.8210\n",
            "129/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 353us/sample - loss: 1.5691 - acc: 0.7644 - val_loss: 1.3114 - val_acc: 0.8370\n",
            "130/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 341us/sample - loss: 1.4858 - acc: 0.7768 - val_loss: 1.2503 - val_acc: 0.8458\n",
            "131/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 363us/sample - loss: 1.5208 - acc: 0.7736 - val_loss: 1.3040 - val_acc: 0.8402\n",
            "132/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 360us/sample - loss: 1.4590 - acc: 0.7792 - val_loss: 1.1356 - val_acc: 0.8580\n",
            "133/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 357us/sample - loss: 1.4909 - acc: 0.7716 - val_loss: 1.1592 - val_acc: 0.8558\n",
            "134/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 353us/sample - loss: 1.4405 - acc: 0.7852 - val_loss: 1.2003 - val_acc: 0.8506\n",
            "135/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 352us/sample - loss: 1.4165 - acc: 0.7910 - val_loss: 1.1696 - val_acc: 0.8532\n",
            "136/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 362us/sample - loss: 1.3691 - acc: 0.7974 - val_loss: 1.1483 - val_acc: 0.8564\n",
            "137/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 342us/sample - loss: 1.3026 - acc: 0.8108 - val_loss: 1.1138 - val_acc: 0.8632\n",
            "138/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 351us/sample - loss: 1.3023 - acc: 0.8092 - val_loss: 1.0521 - val_acc: 0.8694\n",
            "139/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 365us/sample - loss: 1.1942 - acc: 0.8290 - val_loss: 1.0472 - val_acc: 0.8782\n",
            "140/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 356us/sample - loss: 1.2205 - acc: 0.8250 - val_loss: 0.9840 - val_acc: 0.8870\n",
            "141/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 353us/sample - loss: 1.2696 - acc: 0.8208 - val_loss: 1.0180 - val_acc: 0.8804\n",
            "142/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 354us/sample - loss: 1.2249 - acc: 0.8238 - val_loss: 0.9762 - val_acc: 0.8842\n",
            "143/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 356us/sample - loss: 1.2528 - acc: 0.8166 - val_loss: 1.0017 - val_acc: 0.8780\n",
            "144/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 359us/sample - loss: 1.1674 - acc: 0.8318 - val_loss: 0.9503 - val_acc: 0.8798\n",
            "145/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 344us/sample - loss: 1.1209 - acc: 0.8404 - val_loss: 0.9258 - val_acc: 0.8842\n",
            "146/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 358us/sample - loss: 1.1269 - acc: 0.8424 - val_loss: 1.0097 - val_acc: 0.8780\n",
            "147/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 344us/sample - loss: 1.0989 - acc: 0.8440 - val_loss: 0.8966 - val_acc: 0.8900\n",
            "148/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 358us/sample - loss: 1.0515 - acc: 0.8474 - val_loss: 0.8122 - val_acc: 0.9014\n",
            "149/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 352us/sample - loss: 1.1382 - acc: 0.8368 - val_loss: 0.8349 - val_acc: 0.9022\n",
            "150/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 356us/sample - loss: 1.0197 - acc: 0.8526 - val_loss: 0.7733 - val_acc: 0.9150\n",
            "151/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 362us/sample - loss: 1.0189 - acc: 0.8530 - val_loss: 0.8295 - val_acc: 0.9070\n",
            "152/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 352us/sample - loss: 0.9741 - acc: 0.8634 - val_loss: 0.7816 - val_acc: 0.9080\n",
            "153/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 368us/sample - loss: 1.0219 - acc: 0.8574 - val_loss: 0.7891 - val_acc: 0.9160\n",
            "154/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 359us/sample - loss: 0.9605 - acc: 0.8670 - val_loss: 0.7816 - val_acc: 0.9018\n",
            "155/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 375us/sample - loss: 0.9687 - acc: 0.8634 - val_loss: 0.8202 - val_acc: 0.9088\n",
            "156/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 368us/sample - loss: 0.9536 - acc: 0.8652 - val_loss: 0.7048 - val_acc: 0.9152\n",
            "157/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 373us/sample - loss: 0.9424 - acc: 0.8650 - val_loss: 0.7470 - val_acc: 0.9102\n",
            "158/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 364us/sample - loss: 0.9102 - acc: 0.8748 - val_loss: 0.7100 - val_acc: 0.9110\n",
            "159/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 358us/sample - loss: 0.8599 - acc: 0.8858 - val_loss: 0.7025 - val_acc: 0.9182\n",
            "160/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 356us/sample - loss: 0.8587 - acc: 0.8812 - val_loss: 0.7123 - val_acc: 0.9172\n",
            "161/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 356us/sample - loss: 0.8712 - acc: 0.8844 - val_loss: 0.7274 - val_acc: 0.9126\n",
            "162/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 357us/sample - loss: 0.9366 - acc: 0.8640 - val_loss: 0.7458 - val_acc: 0.9064\n",
            "163/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 360us/sample - loss: 0.8364 - acc: 0.8868 - val_loss: 0.6770 - val_acc: 0.9302\n",
            "164/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 358us/sample - loss: 0.8405 - acc: 0.8826 - val_loss: 0.6117 - val_acc: 0.9284\n",
            "165/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 361us/sample - loss: 0.7953 - acc: 0.8916 - val_loss: 0.7307 - val_acc: 0.9128\n",
            "166/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 360us/sample - loss: 0.7882 - acc: 0.8912 - val_loss: 0.6252 - val_acc: 0.9258\n",
            "167/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 367us/sample - loss: 0.8230 - acc: 0.8842 - val_loss: 0.6011 - val_acc: 0.9302\n",
            "168/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 368us/sample - loss: 0.7723 - acc: 0.8978 - val_loss: 0.6165 - val_acc: 0.9252\n",
            "169/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 362us/sample - loss: 0.7470 - acc: 0.8984 - val_loss: 0.6297 - val_acc: 0.9276\n",
            "170/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 365us/sample - loss: 0.7882 - acc: 0.8948 - val_loss: 0.6499 - val_acc: 0.9228\n",
            "171/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 361us/sample - loss: 0.8110 - acc: 0.8896 - val_loss: 0.5594 - val_acc: 0.9364\n",
            "172/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 359us/sample - loss: 0.7370 - acc: 0.9072 - val_loss: 0.5307 - val_acc: 0.9404\n",
            "173/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 359us/sample - loss: 0.7553 - acc: 0.9000 - val_loss: 0.5695 - val_acc: 0.9318\n",
            "174/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 363us/sample - loss: 0.7601 - acc: 0.9004 - val_loss: 0.5773 - val_acc: 0.9266\n",
            "175/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 365us/sample - loss: 0.6863 - acc: 0.9044 - val_loss: 0.5562 - val_acc: 0.9310\n",
            "176/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 357us/sample - loss: 0.7415 - acc: 0.9020 - val_loss: 0.5397 - val_acc: 0.9328\n",
            "177/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 364us/sample - loss: 0.7313 - acc: 0.9000 - val_loss: 0.5598 - val_acc: 0.9342\n",
            "178/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 366us/sample - loss: 0.6840 - acc: 0.9056 - val_loss: 0.5128 - val_acc: 0.9378\n",
            "179/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 362us/sample - loss: 0.6719 - acc: 0.9144 - val_loss: 0.5358 - val_acc: 0.9356\n",
            "180/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 363us/sample - loss: 0.6906 - acc: 0.9072 - val_loss: 0.5330 - val_acc: 0.9332\n",
            "181/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 358us/sample - loss: 0.6627 - acc: 0.9124 - val_loss: 0.4958 - val_acc: 0.9492\n",
            "182/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 357us/sample - loss: 0.6931 - acc: 0.9086 - val_loss: 0.5062 - val_acc: 0.9346\n",
            "183/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 359us/sample - loss: 0.6712 - acc: 0.9098 - val_loss: 0.5151 - val_acc: 0.9406\n",
            "184/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 370us/sample - loss: 0.6162 - acc: 0.9140 - val_loss: 0.4635 - val_acc: 0.9466\n",
            "185/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 356us/sample - loss: 0.5696 - acc: 0.9252 - val_loss: 0.4633 - val_acc: 0.9420\n",
            "186/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 361us/sample - loss: 0.6032 - acc: 0.9208 - val_loss: 0.4763 - val_acc: 0.9378\n",
            "187/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 363us/sample - loss: 0.6377 - acc: 0.9154 - val_loss: 0.4298 - val_acc: 0.9430\n",
            "188/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 383us/sample - loss: 0.6524 - acc: 0.9126 - val_loss: 0.4636 - val_acc: 0.9412\n",
            "189/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 360us/sample - loss: 0.6490 - acc: 0.9156 - val_loss: 0.4124 - val_acc: 0.9530\n",
            "190/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 364us/sample - loss: 0.6393 - acc: 0.9168 - val_loss: 0.4667 - val_acc: 0.9458\n",
            "191/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 360us/sample - loss: 0.5857 - acc: 0.9196 - val_loss: 0.4266 - val_acc: 0.9464\n",
            "192/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 363us/sample - loss: 0.6113 - acc: 0.9154 - val_loss: 0.4023 - val_acc: 0.9488\n",
            "193/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 360us/sample - loss: 0.5618 - acc: 0.9274 - val_loss: 0.4808 - val_acc: 0.9350\n",
            "194/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 358us/sample - loss: 0.5692 - acc: 0.9204 - val_loss: 0.4212 - val_acc: 0.9512\n",
            "195/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 358us/sample - loss: 0.5863 - acc: 0.9212 - val_loss: 0.4625 - val_acc: 0.9430\n",
            "196/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 370us/sample - loss: 0.5415 - acc: 0.9210 - val_loss: 0.4069 - val_acc: 0.9490\n",
            "197/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 368us/sample - loss: 0.5654 - acc: 0.9290 - val_loss: 0.4540 - val_acc: 0.9434\n",
            "198/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 378us/sample - loss: 0.5386 - acc: 0.9274 - val_loss: 0.4114 - val_acc: 0.9470\n",
            "199/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 365us/sample - loss: 0.5272 - acc: 0.9314 - val_loss: 0.3648 - val_acc: 0.9534\n",
            "200/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 357us/sample - loss: 0.5739 - acc: 0.9264 - val_loss: 0.5003 - val_acc: 0.9342\n",
            "201/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 367us/sample - loss: 0.5694 - acc: 0.9238 - val_loss: 0.3322 - val_acc: 0.9580\n",
            "202/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 364us/sample - loss: 0.5391 - acc: 0.9312 - val_loss: 0.3834 - val_acc: 0.9508\n",
            "203/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 370us/sample - loss: 0.5921 - acc: 0.9252 - val_loss: 0.3807 - val_acc: 0.9522\n",
            "204/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 370us/sample - loss: 0.4990 - acc: 0.9288 - val_loss: 0.3316 - val_acc: 0.9594\n",
            "205/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 379us/sample - loss: 0.5521 - acc: 0.9194 - val_loss: 0.4395 - val_acc: 0.9376\n",
            "206/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 370us/sample - loss: 0.5274 - acc: 0.9290 - val_loss: 0.4095 - val_acc: 0.9498\n",
            "207/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 374us/sample - loss: 0.5515 - acc: 0.9286 - val_loss: 0.3645 - val_acc: 0.9526\n",
            "208/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 376us/sample - loss: 0.5198 - acc: 0.9268 - val_loss: 0.3939 - val_acc: 0.9458\n",
            "209/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 372us/sample - loss: 0.5193 - acc: 0.9348 - val_loss: 0.3715 - val_acc: 0.9556\n",
            "210/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 375us/sample - loss: 0.5260 - acc: 0.9312 - val_loss: 0.3942 - val_acc: 0.9536\n",
            "211/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 372us/sample - loss: 0.5048 - acc: 0.9302 - val_loss: 0.3355 - val_acc: 0.9550\n",
            "212/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 377us/sample - loss: 0.4776 - acc: 0.9364 - val_loss: 0.3728 - val_acc: 0.9556\n",
            "213/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 371us/sample - loss: 0.5520 - acc: 0.9286 - val_loss: 0.3627 - val_acc: 0.9494\n",
            "214/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 373us/sample - loss: 0.4644 - acc: 0.9354 - val_loss: 0.4032 - val_acc: 0.9508\n",
            "215/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 375us/sample - loss: 0.4643 - acc: 0.9372 - val_loss: 0.3728 - val_acc: 0.9558\n",
            "216/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 375us/sample - loss: 0.5005 - acc: 0.9344 - val_loss: 0.3956 - val_acc: 0.9510\n",
            "217/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 366us/sample - loss: 0.5160 - acc: 0.9326 - val_loss: 0.4214 - val_acc: 0.9458\n",
            "218/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 372us/sample - loss: 0.4683 - acc: 0.9384 - val_loss: 0.3419 - val_acc: 0.9574\n",
            "219/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 379us/sample - loss: 0.5929 - acc: 0.9252 - val_loss: 0.3366 - val_acc: 0.9560\n",
            "220/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 378us/sample - loss: 0.4968 - acc: 0.9346 - val_loss: 0.3174 - val_acc: 0.9592\n",
            "221/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 365us/sample - loss: 0.4690 - acc: 0.9398 - val_loss: 0.3330 - val_acc: 0.9586\n",
            "222/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 376us/sample - loss: 0.4447 - acc: 0.9398 - val_loss: 0.3923 - val_acc: 0.9582\n",
            "223/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 370us/sample - loss: 0.4911 - acc: 0.9372 - val_loss: 0.3666 - val_acc: 0.9528\n",
            "224/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 373us/sample - loss: 0.5041 - acc: 0.9336 - val_loss: 0.3443 - val_acc: 0.9576\n",
            "225/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 373us/sample - loss: 0.4662 - acc: 0.9378 - val_loss: 0.3272 - val_acc: 0.9582\n",
            "226/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 374us/sample - loss: 0.4194 - acc: 0.9460 - val_loss: 0.2946 - val_acc: 0.9590\n",
            "227/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 373us/sample - loss: 0.5052 - acc: 0.9340 - val_loss: 0.3144 - val_acc: 0.9568\n",
            "228/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 377us/sample - loss: 0.4747 - acc: 0.9360 - val_loss: 0.3116 - val_acc: 0.9638\n",
            "229/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 376us/sample - loss: 0.4256 - acc: 0.9406 - val_loss: 0.3159 - val_acc: 0.9590\n",
            "230/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 370us/sample - loss: 0.4006 - acc: 0.9476 - val_loss: 0.2727 - val_acc: 0.9654\n",
            "231/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 372us/sample - loss: 0.4321 - acc: 0.9426 - val_loss: 0.3338 - val_acc: 0.9524\n",
            "232/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 372us/sample - loss: 0.5441 - acc: 0.9294 - val_loss: 0.3066 - val_acc: 0.9590\n",
            "233/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 375us/sample - loss: 0.4086 - acc: 0.9420 - val_loss: 0.3383 - val_acc: 0.9526\n",
            "234/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 381us/sample - loss: 0.4544 - acc: 0.9412 - val_loss: 0.3293 - val_acc: 0.9580\n",
            "235/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 371us/sample - loss: 0.4431 - acc: 0.9420 - val_loss: 0.3599 - val_acc: 0.9550\n",
            "236/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 372us/sample - loss: 0.4010 - acc: 0.9450 - val_loss: 0.3118 - val_acc: 0.9618\n",
            "237/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 381us/sample - loss: 0.4603 - acc: 0.9394 - val_loss: 0.2960 - val_acc: 0.9626\n",
            "238/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 367us/sample - loss: 0.4326 - acc: 0.9424 - val_loss: 0.3183 - val_acc: 0.9546\n",
            "239/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 372us/sample - loss: 0.4632 - acc: 0.9370 - val_loss: 0.2693 - val_acc: 0.9684\n",
            "240/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 371us/sample - loss: 0.4217 - acc: 0.9436 - val_loss: 0.2961 - val_acc: 0.9626\n",
            "241/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 379us/sample - loss: 0.3728 - acc: 0.9498 - val_loss: 0.3398 - val_acc: 0.9560\n",
            "242/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 382us/sample - loss: 0.4152 - acc: 0.9450 - val_loss: 0.3045 - val_acc: 0.9598\n",
            "243/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 377us/sample - loss: 0.4031 - acc: 0.9470 - val_loss: 0.3747 - val_acc: 0.9556\n",
            "244/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 369us/sample - loss: 0.4501 - acc: 0.9430 - val_loss: 0.3563 - val_acc: 0.9588\n",
            "245/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 378us/sample - loss: 0.4160 - acc: 0.9394 - val_loss: 0.3448 - val_acc: 0.9614\n",
            "246/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 384us/sample - loss: 0.4161 - acc: 0.9492 - val_loss: 0.4135 - val_acc: 0.9486\n",
            "247/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 373us/sample - loss: 0.4076 - acc: 0.9486 - val_loss: 0.2615 - val_acc: 0.9654\n",
            "248/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 375us/sample - loss: 0.3677 - acc: 0.9482 - val_loss: 0.2832 - val_acc: 0.9626\n",
            "249/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 377us/sample - loss: 0.4142 - acc: 0.9436 - val_loss: 0.2990 - val_acc: 0.9582\n",
            "250/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 377us/sample - loss: 0.3851 - acc: 0.9506 - val_loss: 0.3247 - val_acc: 0.9562\n",
            "251/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 377us/sample - loss: 0.3850 - acc: 0.9478 - val_loss: 0.3206 - val_acc: 0.9628\n",
            "252/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 385us/sample - loss: 0.4103 - acc: 0.9422 - val_loss: 0.2855 - val_acc: 0.9624\n",
            "253/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 377us/sample - loss: 0.4179 - acc: 0.9498 - val_loss: 0.3083 - val_acc: 0.9584\n",
            "254/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 393us/sample - loss: 0.4006 - acc: 0.9460 - val_loss: 0.2792 - val_acc: 0.9644\n",
            "255/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 382us/sample - loss: 0.4781 - acc: 0.9404 - val_loss: 0.2985 - val_acc: 0.9610\n",
            "256/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 385us/sample - loss: 0.3702 - acc: 0.9508 - val_loss: 0.3165 - val_acc: 0.9586\n",
            "257/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 401us/sample - loss: 0.4517 - acc: 0.9424 - val_loss: 0.2754 - val_acc: 0.9650\n",
            "258/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 378us/sample - loss: 0.3544 - acc: 0.9538 - val_loss: 0.2667 - val_acc: 0.9676\n",
            "259/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 379us/sample - loss: 0.3821 - acc: 0.9502 - val_loss: 0.2624 - val_acc: 0.9640\n",
            "260/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 378us/sample - loss: 0.4115 - acc: 0.9480 - val_loss: 0.2993 - val_acc: 0.9608\n",
            "261/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 380us/sample - loss: 0.3717 - acc: 0.9538 - val_loss: 0.2532 - val_acc: 0.9638\n",
            "262/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 369us/sample - loss: 0.3713 - acc: 0.9526 - val_loss: 0.2995 - val_acc: 0.9628\n",
            "263/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 382us/sample - loss: 0.3716 - acc: 0.9490 - val_loss: 0.2851 - val_acc: 0.9674\n",
            "264/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 380us/sample - loss: 0.3863 - acc: 0.9480 - val_loss: 0.2584 - val_acc: 0.9668\n",
            "265/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 379us/sample - loss: 0.4103 - acc: 0.9438 - val_loss: 0.2847 - val_acc: 0.9644\n",
            "266/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 383us/sample - loss: 0.4147 - acc: 0.9418 - val_loss: 0.2921 - val_acc: 0.9580\n",
            "267/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 376us/sample - loss: 0.3506 - acc: 0.9586 - val_loss: 0.2771 - val_acc: 0.9666\n",
            "268/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 378us/sample - loss: 0.3714 - acc: 0.9542 - val_loss: 0.2662 - val_acc: 0.9620\n",
            "269/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 373us/sample - loss: 0.4023 - acc: 0.9454 - val_loss: 0.2606 - val_acc: 0.9684\n",
            "270/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 374us/sample - loss: 0.3733 - acc: 0.9494 - val_loss: 0.3559 - val_acc: 0.9590\n",
            "271/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 387us/sample - loss: 0.3274 - acc: 0.9584 - val_loss: 0.2187 - val_acc: 0.9682\n",
            "272/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 385us/sample - loss: 0.4460 - acc: 0.9414 - val_loss: 0.3778 - val_acc: 0.9616\n",
            "273/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 366us/sample - loss: 0.4083 - acc: 0.9492 - val_loss: 0.3049 - val_acc: 0.9654\n",
            "274/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 386us/sample - loss: 0.3725 - acc: 0.9484 - val_loss: 0.3091 - val_acc: 0.9610\n",
            "275/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 381us/sample - loss: 0.3637 - acc: 0.9518 - val_loss: 0.2267 - val_acc: 0.9714\n",
            "276/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 380us/sample - loss: 0.3621 - acc: 0.9482 - val_loss: 0.2503 - val_acc: 0.9708\n",
            "277/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 377us/sample - loss: 0.3660 - acc: 0.9506 - val_loss: 0.2602 - val_acc: 0.9694\n",
            "278/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 382us/sample - loss: 0.4212 - acc: 0.9500 - val_loss: 0.3444 - val_acc: 0.9500\n",
            "279/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 379us/sample - loss: 0.4284 - acc: 0.9396 - val_loss: 0.2420 - val_acc: 0.9684\n",
            "280/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 378us/sample - loss: 0.3031 - acc: 0.9568 - val_loss: 0.2737 - val_acc: 0.9676\n",
            "281/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 363us/sample - loss: 0.3880 - acc: 0.9504 - val_loss: 0.2385 - val_acc: 0.9662\n",
            "282/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 383us/sample - loss: 0.4201 - acc: 0.9426 - val_loss: 0.3132 - val_acc: 0.9598\n",
            "283/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 377us/sample - loss: 0.3617 - acc: 0.9514 - val_loss: 0.2529 - val_acc: 0.9680\n",
            "284/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 391us/sample - loss: 0.3589 - acc: 0.9506 - val_loss: 0.2541 - val_acc: 0.9678\n",
            "285/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 387us/sample - loss: 0.4218 - acc: 0.9514 - val_loss: 0.3274 - val_acc: 0.9554\n",
            "286/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 373us/sample - loss: 0.4128 - acc: 0.9494 - val_loss: 0.2579 - val_acc: 0.9718\n",
            "287/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 380us/sample - loss: 0.3744 - acc: 0.9506 - val_loss: 0.3306 - val_acc: 0.9614\n",
            "288/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 382us/sample - loss: 0.4074 - acc: 0.9468 - val_loss: 0.2013 - val_acc: 0.9732\n",
            "289/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 380us/sample - loss: 0.3495 - acc: 0.9544 - val_loss: 0.2247 - val_acc: 0.9726\n",
            "290/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 386us/sample - loss: 0.3276 - acc: 0.9572 - val_loss: 0.2115 - val_acc: 0.9758\n",
            "291/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 384us/sample - loss: 0.3133 - acc: 0.9590 - val_loss: 0.2085 - val_acc: 0.9742\n",
            "292/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 388us/sample - loss: 0.3492 - acc: 0.9550 - val_loss: 0.2269 - val_acc: 0.9702\n",
            "293/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 381us/sample - loss: 0.3022 - acc: 0.9606 - val_loss: 0.2240 - val_acc: 0.9682\n",
            "294/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 388us/sample - loss: 0.3938 - acc: 0.9494 - val_loss: 0.2308 - val_acc: 0.9698\n",
            "295/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 374us/sample - loss: 0.3687 - acc: 0.9484 - val_loss: 0.2513 - val_acc: 0.9674\n",
            "296/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 394us/sample - loss: 0.3430 - acc: 0.9544 - val_loss: 0.2379 - val_acc: 0.9714\n",
            "297/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 389us/sample - loss: 0.3843 - acc: 0.9496 - val_loss: 0.2725 - val_acc: 0.9660\n",
            "298/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 382us/sample - loss: 0.3917 - acc: 0.9500 - val_loss: 0.3149 - val_acc: 0.9616\n",
            "299/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 380us/sample - loss: 0.3312 - acc: 0.9576 - val_loss: 0.2541 - val_acc: 0.9766\n",
            "300/300\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "5000/5000 [==============================] - 2s 386us/sample - loss: 0.3273 - acc: 0.9546 - val_loss: 0.2775 - val_acc: 0.9610\n",
            "Train set: Loss=0.2508 ; Accuracy=96.4%\n",
            "Test set: Loss=33.9916 ; Accuracy=2.0%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_22dabf7a-8602-4007-9696-6864ca245f7a\", \"embeddings.csv\", 1902212)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UI61hVlyQLS",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "ded56b83-ecad-4200-d78f-9abf58a6dfa3"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8c5f80ee-a7d5-46e1-be20-2fbfc6878181\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8c5f80ee-a7d5-46e1-be20-2fbfc6878181\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wurA3IXNliMy"
      },
      "source": [
        "embeddings = Embeddings(read_embeddings('embeddings.csv'))\n",
        "\n",
        "state_space_size = embeddings.size() * history_length\n",
        "action_space_size = embeddings.size() * ra_length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RP4vzcHwOmbP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe7e9827-677d-4ac9-f25a-63cb57566a27"
      },
      "source": [
        "environment = Environment(data, embeddings, alpha, gamma, fixed_length)\n",
        "\n",
        "tf.reset_default_graph() ## For multiple consecutive executions\n",
        "\n",
        "sess = tf.Session()\n",
        "## '1: Initialize actor network f_θ^π and critic network Q(s, a|θ^µ) with random weights'\n",
        "actor = Actor(sess, state_space_size, action_space_size, batch_size, ra_length, history_length, embeddings.size(), tau, actor_lr)\n",
        "critic = Critic(sess, state_space_size, action_space_size, history_length, embeddings.size(), tau, critic_lr)\n",
        "\n",
        "train(sess, environment, actor, critic, embeddings, history_length, ra_length, buffer_size, batch_size, discount_factor, nb_episodes, filename_summary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-9-010cb85f878d>:70: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From <ipython-input-9-010cb85f878d>:56: calling map_fn (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:69: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:573: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  initializer=self._kernel_initializer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:579: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  tf.compat.v1.constant_initializer(1.0, dtype=self.dtype)))\n",
            "/usr/local/lib/python3.7/dist-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:583: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  initializer=self._kernel_initializer)\n",
            "/usr/local/lib/python3.7/dist-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:589: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  tf.compat.v1.zeros_initializer(dtype=self.dtype)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-9-010cb85f878d>:40: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:64: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1/10 Reward=541 Time=6s No replay\n",
            "Episode 2/10 Reward=541 Time=70s Loss=1065.4207\n",
            "Episode 3/10 Reward=541 Time=91s Loss=103.1924\n",
            "Episode 4/10 Reward=541 Time=89s Loss=71.4424\n",
            "Episode 5/10 Reward=541 Time=88s Loss=60.6218\n",
            "Episode 6/10 Reward=541 Time=90s Loss=46.9305\n",
            "Episode 7/10 Reward=541 Time=89s Loss=36.3469\n",
            "Episode 8/10 Reward=541 Time=88s Loss=41.4545\n",
            "Episode 9/10 Reward=541 Time=88s Loss=26.6860\n",
            "Episode 10/10 Reward=541 Time=89s Loss=24.7709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOnK_UxHzaPa"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsJ0klBBSSXn"
      },
      "source": [
        "dict_embeddings = {}\n",
        "for i, item in enumerate(embeddings.get_embedding_vector()):\n",
        "  str_item = str(item)\n",
        "  assert(str_item not in dict_embeddings)\n",
        "  dict_embeddings[str_item] = i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-LsmlHnyouJ"
      },
      "source": [
        "def state_to_items(state, actor, ra_length, embeddings, dict_embeddings, target=False):\n",
        "  return [dict_embeddings[str(action)]\n",
        "          for action in actor.get_recommendation_list(ra_length, np.array(state).reshape(1, -1), embeddings, target).reshape(ra_length, embeddings.size())]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnCn8bf58uAP"
      },
      "source": [
        "def test_actor(actor, test_df, embeddings, dict_embeddings, ra_length, history_length, target=False, nb_rounds=1):\n",
        "  ratings = []\n",
        "  unknown = 0\n",
        "  random_seen = []\n",
        "  for _ in range(nb_rounds):\n",
        "    for i in range(len(test_df)):\n",
        "      history_sample = list(test_df[i].sample(history_length)['itemId'])\n",
        "      recommendation = state_to_items(embeddings.embed(history_sample), actor, ra_length, embeddings, dict_embeddings, target)\n",
        "      for item in recommendation:\n",
        "        l = list(test_df[i].loc[test_df[i]['itemId'] == item]['rating'])\n",
        "        assert(len(l) < 2)\n",
        "        if len(l) == 0:\n",
        "          unknown += 1\n",
        "        else:\n",
        "          ratings.append(l[0])\n",
        "      for item in history_sample:\n",
        "        random_seen.append(list(test_df[i].loc[test_df[i]['itemId'] == item]['rating'])[0])\n",
        "\n",
        "  return ratings, unknown, random_seen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0j3nHjUAP24"
      },
      "source": [
        "## Train set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBZr_opifZss"
      },
      "source": [
        "#### Target = False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgqFYAsd8W-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6220c26f-75a6-45a1-e330-73dd1a765418"
      },
      "source": [
        "ratings, unknown, random_seen = test_actor(actor, dg.train, embeddings, dict_embeddings, ra_length, history_length, target=False, nb_rounds=10)\n",
        "print('%0.1f%% unknown' % (100 * unknown / (len(ratings) + unknown)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "84.7% unknown\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGetmkeD95rP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "2915d188-49ee-4e68-f1f0-97b13fe04f79"
      },
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(ratings)\n",
        "plt.title('Predictions ; Mean = %.4f' % (np.mean(ratings)))\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(random_seen)\n",
        "plt.title('Random ; Mean = %.4f' % (np.mean(random_seen)))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FPKh8gafdcn"
      },
      "source": [
        "#### Target = True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvjYl_LTfGi9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48f642b8-22fd-432f-ee55-e3ccf388acbc"
      },
      "source": [
        "ratings, unknown, random_seen = test_actor(actor, dg.train, embeddings, dict_embeddings, ra_length, history_length, target=True, nb_rounds=10)\n",
        "print('%0.1f%% unknown' % (100 * unknown / (len(ratings) + unknown)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85.9% unknown\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IKYVQ6gfIXk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "7c4e938a-6888-47cd-ec33-fbb16254ef34"
      },
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(ratings)\n",
        "plt.title('Predictions ; Mean = %.4f' % (np.mean(ratings)))\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(random_seen)\n",
        "plt.title('Random ; Mean = %.4f' % (np.mean(random_seen)))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFimdOkLASAn"
      },
      "source": [
        "## Test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x49sZSZIfgfN"
      },
      "source": [
        "#### Target = False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXhBwo6t-p5R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf7bd12a-6898-4eb0-ace5-7888c6c05e0c"
      },
      "source": [
        "ratings, unknown, random_seen = test_actor(actor, dg.test, embeddings, dict_embeddings, ra_length, history_length, target=False, nb_rounds=10)\n",
        "print('%0.1f%% unknown' % (100 * unknown / (len(ratings) + unknown)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "84.7% unknown\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFPjENrZAVsc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "e100a92c-6480-43f4-fd70-f67443a0b4fe"
      },
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(ratings)\n",
        "plt.title('Predictions ; Mean = %.4f' % (np.mean(ratings)))\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(random_seen)\n",
        "plt.title('Random ; Mean = %.4f' % (np.mean(random_seen)))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wg4QPFo7fkzn"
      },
      "source": [
        "#### Target = True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HCCXmcsAYkK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d87cf7d-7ee3-4709-b022-ba376a670e35"
      },
      "source": [
        "ratings, unknown, random_seen = test_actor(actor, dg.test, embeddings, dict_embeddings, ra_length, history_length, target=True, nb_rounds=10)\n",
        "print('%0.1f%% unknown' % (100 * unknown / (len(ratings) + unknown)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "86.3% unknown\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5T4zKcJfTa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "79b9caf6-a1e3-43ab-b5c7-3ba81162d6c4"
      },
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(ratings)\n",
        "plt.title('Predictions ; Mean = %.4f' % (np.mean(ratings)))\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(random_seen)\n",
        "plt.title('Random ; Mean = %.4f' % (np.mean(random_seen)))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}